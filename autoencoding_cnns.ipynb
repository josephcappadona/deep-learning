{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unsupervised learning of features in a video database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as pre\n",
    "import numpy as np\n",
    "import time\n",
    "from math import ceil\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Batcher:\n",
    "    batch_size: int\n",
    "    X_train: np.array\n",
    "    y_train: np.array\n",
    "    X_test: np.array\n",
    "    y_test: np.array\n",
    "        \n",
    "    def train_batch(self):\n",
    "        train_ds = \\\n",
    "            tf.data.Dataset.from_tensor_slices(\n",
    "                (self.X_train, self.y_train)\n",
    "            ).shuffle(10000).batch(batch_size=self.batch_size, drop_remainder=False)\n",
    "        return train_ds\n",
    "    \n",
    "    def test_batch(self):\n",
    "        test_ds = \\\n",
    "            tf.data.Dataset.from_tensor_slices(\n",
    "                (self.X_test, self.y_test)\n",
    "            ).batch(batch_size=self.batch_size, drop_remainder=False)\n",
    "        return test_ds\n",
    "    \n",
    "    def num_train_batches(self):\n",
    "        return int(ceil(self.X_train.shape[0] / self.batch_size))\n",
    "    \n",
    "    def num_test_batches(self):\n",
    "        return int(ceil(self.X_test.shape[0] / self.batch_size))\n",
    "    \n",
    "def early_stopping_check(epoch, train_history, min_delta, patience_count,\n",
    "                         patience):\n",
    "    if epoch > 1 and train_history[-2][-2] - train_history[-1][-2] \\\n",
    "            > min_delta:\n",
    "        patience_count = 0\n",
    "    else:\n",
    "        patience_count += 1\n",
    "\n",
    "    return patience_count, (patience_count > patience)\n",
    "    \n",
    "@dataclass\n",
    "class Trainer:\n",
    "    \"\"\"Binds a model, databunch, and config for training purposes.\n",
    "  \n",
    "      Ideally Dash app can work with this object without reference to\n",
    "      underlying model\n",
    "      type.\n",
    "      \"\"\"\n",
    "\n",
    "    model: tf.keras.models.Model\n",
    "    batcher: Batcher\n",
    "    optimizer: tf.keras.optimizers.Optimizer = tf.keras.optimizers.Adam\n",
    "    loss_function: tf.keras.metrics.Metric = tf.keras.losses.BinaryCrossentropy\n",
    "    batch_size: int = 128\n",
    "    num_epochs: int = 25\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.optimizer = self.optimizer()\n",
    "        self.loss_function = self.loss_function()\n",
    "        self.train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_loss')\n",
    "        self.test_loss = tf.keras.metrics.BinaryCrossentropy(name='test_loss')\n",
    "\n",
    "        self.train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "        self.test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "\n",
    "        self.train_auc = tf.keras.metrics.AUC(name='train_auc', num_thresholds=1000)\n",
    "        self.test_auc = tf.keras.metrics.AUC(name='train_auc', num_thresholds=1000)\n",
    "\n",
    "        self.trained = False\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, type(self)):\n",
    "            return ((self.model, self.loss_function, self.optimizer,\n",
    "                     self.train_loss, self.train_accuracy, self.train_auc,\n",
    "                     self.test_loss, self.test_accuracy, self.test_auc) ==\n",
    "                    (other.model, other.loss_function, other.optimizer,\n",
    "                     other.train_loss, other.train_accuracy, other.train_auc,\n",
    "                     other.test_loss, other.test_accuracy, other.test_auc))\n",
    "        return NotImplemented\n",
    "\n",
    "    def __hash__(self):\n",
    "        return (hash(self.model) ^ hash(self.loss_function) ^ hash(self.optimizer)\n",
    "                ^ hash(self.train_loss) ^ hash(self.train_accuracy) ^\n",
    "                hash(self.train_auc) ^ hash(self.test_loss) ^\n",
    "                hash(self.test_accuracy) ^ hash(self.test_auc) ^\n",
    "                hash((self.model, self.loss_function, self.optimizer,\n",
    "                      self.train_loss, self.train_accuracy, self.train_auc,\n",
    "                      self.test_loss, self.test_accuracy, self.test_auc)))\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, observations, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(observations)\n",
    "            loss = self.loss_function(labels, predictions)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients,\n",
    "                                           self.model.trainable_variables))\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, observations, labels):\n",
    "        predictions = self.model(observations)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.train_loss.reset_states()\n",
    "        self.train_accuracy.reset_states()\n",
    "        self.test_loss.reset_states()\n",
    "        self.test_accuracy.reset_states()\n",
    "\n",
    "    def fit(self):\n",
    "        # transforms = get_transforms_from_config(self.config)\n",
    "        if self.trained:\n",
    "            metrics_dict = {\n",
    "                'Train Loss': self.train_loss.result().numpy(),\n",
    "                'Train Accuracy': self.train_accuracy.result().numpy()}\n",
    "            return metrics_dict\n",
    "\n",
    "        train_batched = self.batcher.train_batch()\n",
    "        test_batched = self.batcher.test_batch()\n",
    "\n",
    "        train_history = []\n",
    "        patience_count = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print(f'{epoch+1} / {self.num_epochs}')\n",
    "            self.reset_states()\n",
    "\n",
    "            for i, (observations, labels) in enumerate(train_batched):\n",
    "                prev_time = time.time()\n",
    "                self.train_step(observations, labels)\n",
    "                duration = time.time() - prev_time\n",
    "                print(f'\\t{i+1} / {self.batcher.num_train_batches()} ({duration:.2f})s')\n",
    "\n",
    "            for test_observations, test_labels in test_batched:\n",
    "                self.test_step(test_observations, test_labels)\n",
    "\n",
    "        self.trained = True\n",
    "        return self.model\n",
    "\n",
    "    def eval(self):\n",
    "        self.reset_states()\n",
    "        _, test_batch = self.batcher.test_batch(self.batch_size)\n",
    "        for observations, labels in test_batch:\n",
    "            self.test_step(observations, labels)\n",
    "\n",
    "        metrics_dict = dict(test_loss=self.test_loss.result().numpy(),\n",
    "                            test_accuracy=self.test_accuracy.result().numpy(),\n",
    "                            test_auc=self.test_auc.result().numpy())\n",
    "        return metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# example of a CNN model with an identity or projection residual module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, add, UpSampling2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    " \n",
    "# function for creating an identity or projection residual module\n",
    "def residual_module(layer_in, n_filters):\n",
    "    merge_input = layer_in\n",
    "    # check if the number of filters needs to be increase, assumes channels last format\n",
    "    if layer_in.shape[-1] != n_filters:\n",
    "        merge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "    # conv1\n",
    "    conv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "    # conv2\n",
    "    conv2 = Conv2D(n_filters, (3,3), padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n",
    "    # add filters, assumes filters/channels last\n",
    "    layer_out = add([conv2, merge_input])\n",
    "    # activation function\n",
    "    layer_out = Activation('relu')(layer_out)\n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model input\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (2,2), padding='same', activation='relu', kernel_initializer='he_normal')(input_img)\n",
    "x = residual_module(x, 8)\n",
    "x = residual_module(x, 16)\n",
    "x = residual_module(x, 32)\n",
    "x = residual_module(x, 64)\n",
    "x = AveragePooling2D((2, 2))(x)\n",
    "\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = residual_module(x, 64)\n",
    "x = residual_module(x, 32)\n",
    "x = residual_module(x, 16)\n",
    "x = residual_module(x, 8)\n",
    "x = Conv2D(1, (2,2), padding='same', activation='relu', kernel_initializer='he_normal')(x)\n",
    "\n",
    "\n",
    "autoencoder = Model(input_img, x)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1\n",
      "\t1 / 469 (2.57)s\n",
      "\t2 / 469 (1.34)s\n",
      "\t3 / 469 (1.26)s\n",
      "\t4 / 469 (1.25)s\n",
      "\t5 / 469 (1.32)s\n",
      "\t6 / 469 (1.33)s\n",
      "\t7 / 469 (1.29)s\n",
      "\t8 / 469 (1.25)s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-3102042bb802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-109-52bf42d7e545>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mprev_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprev_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\t{i+1} / {self.batcher.num_train_batches()} ({duration:.2f})s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batcher = Batcher(128, X_train, X_train, X_test, X_test)\n",
    "trainer = Trainer(autoencoder, batcher, num_epochs=1)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      " 1024/60000 [..............................] - ETA: 9:55"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a086a01136c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/demo-qfKwvgY4/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, batch_size=1024, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(X_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
