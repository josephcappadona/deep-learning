{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencv video example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('armada_vs_hbox.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19722\n"
     ]
    }
   ],
   "source": [
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 99)\n",
    "res, frame = cap.read()\n",
    "Image.fromarray(frame[...,::-1], 'RGB').resize((256, 256)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(im, desired_size, maintain_aspect_ratio=True, padding_color=(0, 0, 0)):\n",
    "    # adapted from https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/#using-opencv\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # new_size should be in (width, height) format\n",
    "\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "        value=padding_color)\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape)\n",
    "print(resize(frame, 256).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def sample_frames_from_video(video, k, technique='random'):\n",
    "    if isinstance(video, str):\n",
    "        cap = cv2.VideoCapture(video)\n",
    "    elif isinstance(video, cv2.VideoCapture):\n",
    "        cap = video\n",
    "    else:\n",
    "        raise TypeError(f'Illegal type f{video.__class__.__name__} for argument `video`, must be str or cv2.VideoCapture.')\n",
    "    \n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    k = min(k, n_frames)\n",
    "    \n",
    "    if technique == 'first':\n",
    "        idxs = list(range(k))\n",
    "    elif technique == 'random':\n",
    "        idxs = random.sample(range(n_frames), k)\n",
    "    \n",
    "    frames = []\n",
    "    for idx in idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        _, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "        \n",
    "    return idxs, np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12931, 8957, 9308, 13901, 9584, 11319, 15670, 18072, 10164, 5897]\n",
      "(10, 720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "idxs, frames = sample_frames_from_video('armada_vs_hbox.mp4', 10)\n",
    "print(idxs)\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_bbox(im):\n",
    "    shape = im.shape\n",
    "    x_min, x_max = sorted([random.randrange(0, im.shape[0]+1) for _ in range(2)])\n",
    "    y_min, y_max = sorted([random.randrange(0, im.shape[1]+1) for _ in range(2)])\n",
    "    return (x_min, x_max), (y_min, y_max)\n",
    "\n",
    "def get_bboxes(im, window):\n",
    "    shape = w, h = im.shape[:2]\n",
    "    bboxes = []\n",
    "    for x0 in range(0, w, window):\n",
    "        for y0 in range(0, h, window):\n",
    "            bboxes.append(((x0, x0+window), (y0, y0+window)))\n",
    "    return bboxes\n",
    "\n",
    "def crop(im, x_min, x_max, y_min, y_max):\n",
    "    return im[x_min:x_max, y_min:y_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "windows = [512, 384, 256, 192, 128, 96, 64, 48, 32, 24, 16]\n",
    "bboxes = []\n",
    "for window in windows:\n",
    "    bboxes.extend(get_bboxes(im, window))\n",
    "print(len(bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = frames[0]\n",
    "(x_min, x_max), (y_min, y_max) = bboxes[0]\n",
    "im = crop(im, x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(im, 'RGB').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, channels = frames.shape[1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(frames, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches train=4, test=1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             zoom_range=0.1)\n",
    "datagen.fit(X_train)\n",
    "train_iterator = datagen.flow(X_train, X_train, batch_size=32)\n",
    "test_iterator = datagen.flow(X_test, X_test, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "https://keras.io/examples/mnist_denoising_autoencoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
